{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WREb-GwCDjON"
      },
      "source": [
        "# Hierarchically Deep Convolutional Neural Network For Image Recognition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sIMFIbzkDjOP"
      },
      "source": [
        "## Setup and Imports"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bK2YfMDWDjOP"
      },
      "source": [
        "**Import Packages**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o8jkSNBTDjOQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3d717c8-6bad-419a-8b8d-0d0b5163df3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ]
        }
      ],
      "source": [
        "import keras as kr\n",
        "import numpy as np\n",
        "import tensorflow.compat.v1 as tf\n",
        "\n",
        "tf.disable_v2_behavior()\n",
        "\n",
        "\n",
        "from keras.datasets import cifar100\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from random import randint\n",
        "import time\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cIywIdtKDjOR"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists('data/models/'):\n",
        "    os.mkdir('data/models')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OcpoTSj4DjOR"
      },
      "source": [
        "**Define Global Variables**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m00DWErIDjOS"
      },
      "outputs": [],
      "source": [
        "# The number of coarse categories\n",
        "coarse_categories = 9\n",
        "\n",
        "# The number of fine categories\n",
        "fine_categories = 25"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gr7TENfZDjOT"
      },
      "source": [
        "## Import and Preprocess Dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import keras_preprocessing.image\n",
        "\n",
        "def load_and_crop_img(path, grayscale=False, color_mode='rgb', target_size=None,\n",
        "             interpolation='nearest'):\n",
        "    \"\"\"Wraps keras_preprocessing.image.utils.loag_img() and adds cropping.\n",
        "    Cropping method enumarated in interpolation\n",
        "    # Arguments\n",
        "        path: Path to image file.\n",
        "        color_mode: One of \"grayscale\", \"rgb\", \"rgba\". Default: \"rgb\".\n",
        "            The desired image format.\n",
        "        target_size: Either `None` (default to original size)\n",
        "            or tuple of ints `(img_height, img_width)`.\n",
        "        interpolation: Interpolation and crop methods used to resample and crop the image\n",
        "            if the target size is different from that of the loaded image.\n",
        "            Methods are delimited by \":\" where first part is interpolation and second is crop\n",
        "            e.g. \"lanczos:random\".\n",
        "            Supported interpolation methods are \"nearest\", \"bilinear\", \"bicubic\", \"lanczos\",\n",
        "            \"box\", \"hamming\" By default, \"nearest\" is used.\n",
        "            Supported crop methods are \"none\", \"center\", \"random\".\n",
        "    # Returns\n",
        "        A PIL Image instance.\n",
        "    # Raises\n",
        "        ImportError: if PIL is not available.\n",
        "        ValueError: if interpolation method is not supported.\n",
        "    \"\"\"\n",
        "\n",
        "    # Decode interpolation string. Allowed Crop methods: none, center, random\n",
        "    interpolation, crop = interpolation.split(\":\") if \":\" in interpolation else (interpolation, \"none\")  \n",
        "\n",
        "    if crop == \"none\":\n",
        "        return keras_preprocessing.image.utils.load_img(path, \n",
        "                                            grayscale=grayscale, \n",
        "                                            color_mode=color_mode, \n",
        "                                            target_size=target_size,\n",
        "                                            interpolation=interpolation)\n",
        "\n",
        "    # Load original size image using Keras\n",
        "    img = keras_preprocessing.image.utils.load_img(path, \n",
        "                                            grayscale=grayscale, \n",
        "                                            color_mode=color_mode, \n",
        "                                            target_size=None, \n",
        "                                            interpolation=interpolation)\n",
        "\n",
        "    # Crop fraction of total image\n",
        "    crop_fraction = 0.875\n",
        "    target_width = target_size[1]\n",
        "    target_height = target_size[0]\n",
        "\n",
        "    if target_size is not None:        \n",
        "        if img.size != (target_width, target_height):\n",
        "\n",
        "            if crop not in [\"center\", \"random\"]:\n",
        "                raise ValueError('Invalid crop method {} specified.', crop)\n",
        "\n",
        "            if interpolation not in keras_preprocessing.image.utils._PIL_INTERPOLATION_METHODS:\n",
        "                raise ValueError(\n",
        "                    'Invalid interpolation method {} specified. Supported '\n",
        "                    'methods are {}'.format(interpolation,\n",
        "                        \", \".join(keras_preprocessing.image.utils._PIL_INTERPOLATION_METHODS.keys())))\n",
        "            \n",
        "            resample = keras_preprocessing.image.utils._PIL_INTERPOLATION_METHODS[interpolation]\n",
        "\n",
        "            width, height = img.size\n",
        "\n",
        "            # Resize keeping aspect ratio\n",
        "            # result shold be no smaller than the targer size, include crop fraction overhead\n",
        "            target_size_before_crop = (target_width/crop_fraction, target_height/crop_fraction)\n",
        "            ratio = max(target_size_before_crop[0] / width, target_size_before_crop[1] / height)\n",
        "            target_size_before_crop_keep_ratio = int(width * ratio), int(height * ratio)\n",
        "            img = img.resize(target_size_before_crop_keep_ratio, resample=resample)\n",
        "\n",
        "            width, height = img.size\n",
        "\n",
        "            if crop == \"center\":\n",
        "                left_corner = int(round(width/2)) - int(round(target_width/2))\n",
        "                top_corner = int(round(height/2)) - int(round(target_height/2))\n",
        "                return img.crop((left_corner, top_corner, left_corner + target_width, top_corner + target_height))\n",
        "            elif crop == \"random\":\n",
        "                left_shift = random.randint(0, int((width - target_width)))\n",
        "                down_shift = random.randint(0, int((height - target_height)))\n",
        "                return img.crop((left_shift, down_shift, target_width + left_shift, target_height + down_shift))\n",
        "\n",
        "    return img\n",
        "  \n",
        "keras_preprocessing.image.iterator.load_img = load_and_crop_img"
      ],
      "metadata": {
        "id": "VorDvH9A5TlK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications.inception_v3 import preprocess_input\n",
        "fine_datagen = tf.keras.preprocessing.image.ImageDataGenerator(    \n",
        "    rotation_range=15,\n",
        "    horizontal_flip=True,\n",
        "    samplewise_std_normalization = True)\n",
        "fine_dir = \"/content/drive/MyDrive/CS135_final_data/fine\"\n",
        "fine_img = fine_datagen.flow_from_directory(fine_dir,target_size=(128, 128), interpolation = 'lanczos:center')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmgxfscyDJy7",
        "outputId": "be434b32-2f8a-411a-bdee-110f2ec39ca0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/image_data_generator.py:356: UserWarning: This ImageDataGenerator specifies `samplewise_std_normalization`, which overrides setting of `samplewise_center`.\n",
            "  warnings.warn('This ImageDataGenerator specifies '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 10116 images belonging to 25 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJqRFYqGI0-0",
        "outputId": "f80d0293-4923-426b-acfd-a029b20ea1e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "batch_size=32\n",
        "fine_img.reset()\n",
        "X_fine, y_fine = next(fine_img)\n",
        "for i in tqdm(range(int(len(fine_img))-1)): #1st batch is already fetched before the for loop.\n",
        "  img, label = next(fine_img)\n",
        "  X_fine = np.append(X_fine, img, axis=0)\n",
        "  y_fine = np.append(y_fine, label, axis=0)\n",
        "print(X_fine.shape, y_fine.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gD4-pUyc8xKs",
        "outputId": "06e0955e-d7d5-4247-c109-362376a13929"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 316/316 [2:21:11<00:00, 26.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10116, 128, 128, 3) (10116, 25)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdHFpIM6DjOV"
      },
      "source": [
        "**Fine-To-Coarse Mapping**\n",
        "\n",
        "(Ideally, this would be done through spectral clustering as opposed to hard-coding)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fine2coarse = np.zeros((fine_categories,coarse_categories))\n",
        "fine2coarse[0,0] = 1\n",
        "fine2coarse[1,5] = 1\n",
        "fine2coarse[2,5] = 1\n",
        "fine2coarse[3,0] = 1\n",
        "fine2coarse[4,4] = 1\n",
        "fine2coarse[5,4] = 1\n",
        "fine2coarse[6,3] = 1\n",
        "fine2coarse[7,6] = 1\n",
        "fine2coarse[8,4] = 1\n",
        "fine2coarse[9,2] = 1\n",
        "fine2coarse[10,5] = 1\n",
        "fine2coarse[11,4] = 1\n",
        "fine2coarse[12,8] = 1\n",
        "fine2coarse[13,5] = 1\n",
        "fine2coarse[14,4] = 1\n",
        "fine2coarse[15,2] = 1\n",
        "fine2coarse[16,4] = 1\n",
        "fine2coarse[17,6] = 1\n",
        "fine2coarse[18,7] = 1\n",
        "fine2coarse[19,3] = 1\n",
        "fine2coarse[20,8] = 1\n",
        "fine2coarse[21,5] = 1\n",
        "fine2coarse[22,1] = 1\n",
        "fine2coarse[23,5] = 1\n",
        "fine2coarse[24,6] = 1"
      ],
      "metadata": {
        "id": "Otsr8Emw0yv2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with np.printoptions(threshold=np.inf):\n",
        "    print(fine2coarse)"
      ],
      "metadata": {
        "id": "E5H6y_PEaOMC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33-wnYgdDjOZ"
      },
      "source": [
        "**Split Training set into Training and Validation sets**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "elDqccurDjOZ"
      },
      "outputs": [],
      "source": [
        "x_train, x_val, y_train, y_val = train_test_split(X_fine, y_fine, test_size=.2,shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-KiVs17ihLW",
        "outputId": "5489edaa-fc8b-4fa4-af41-f98f6b958455"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8092, 128, 128, 3)\n",
            "(8092, 25)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from IPython.core.display import display, HTML\n",
        "\n",
        "for i in range(0,10):\n",
        "    image = x_train[i]\n",
        "    plt.imshow(image)\n",
        "    plt.show()\n",
        "    print(np.where(y_train[i] == 1)[0])\n",
        "\n",
        "\n",
        "for i in range(0,10):\n",
        "    image = x_val[i]\n",
        "    plt.imshow(image)\n",
        "    plt.show()\n",
        "    print(np.where(y_train[i] == 1)[0])"
      ],
      "metadata": {
        "id": "WTmCiLQwjVx1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_fine_eight = y_fine[np.argwhere(y_fine==1)[:,1] < 8]\n",
        "X_fine_eight = X_fine[np.argwhere(y_fine==1)[:,1] < 8]\n",
        "x_train_eight, x_val_eight, y_train_eight, y_val_eight = train_test_split(X_fine_eight, y_fine_eight, test_size=.1,shuffle=True)"
      ],
      "metadata": {
        "id": "GsYVTQhoVnrF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8oUI-QnFDjOc"
      },
      "source": [
        "**Constructing CNN**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ILCBmsHkDjOc"
      },
      "outputs": [],
      "source": [
        "from keras import optimizers\n",
        "from keras.layers import Input, Conv2D, Dropout, MaxPooling2D, Flatten, Dense, BatchNormalization\n",
        "from keras.models import Model\n",
        "\n",
        "in_layer = Input(shape=(128, 128, 3), dtype='float32', name='main_input')\n",
        "\n",
        "net = Conv2D(64, 3, strides=1, padding='same', activation='relu')(in_layer)\n",
        "net = BatchNormalization()(net)\n",
        "net = MaxPooling2D((2, 2), padding='valid')(net)\n",
        "\n",
        "net = Conv2D(128, 3, strides=1, padding='same', activation='relu')(net)\n",
        "net = BatchNormalization()(net)\n",
        "# net = Dropout(.3)(net)\n",
        "net = MaxPooling2D((2, 2), padding='valid')(net)\n",
        "\n",
        "net = Conv2D(256, 3, strides=1, padding='same', activation='relu')(net)\n",
        "net = BatchNormalization()(net)\n",
        "# net = Dropout(.4)(net)\n",
        "net = MaxPooling2D((2, 2), padding='valid')(net)\n",
        "\n",
        "net = Conv2D(512, 3, strides=1, padding='same', activation='relu')(net)\n",
        "net = BatchNormalization()(net)\n",
        "# net = Dropout(.5)(net)\n",
        "net = MaxPooling2D((2, 2), padding='valid')(net)\n",
        "\n",
        "net = Flatten()(net)\n",
        "\n",
        "net = Dense(1024, activation='relu')(net)\n",
        "net = BatchNormalization()(net)\n",
        "net = Dropout(.3)(net)\n",
        "net = Dense(25, activation='softmax')(net)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import gc\n",
        "dir_path = '/content/data/models'\n",
        "dir_path1 = '/content/data/graph'\n",
        "\n",
        "try:\n",
        "    shutil.rmtree(dir_path)\n",
        "\n",
        "except OSError as e:\n",
        "    print(\"Error: %s : %s\" % (dir_path, e.strerror))\n",
        "\n",
        "try:\n",
        "    shutil.rmtree(dir_path1)\n",
        "\n",
        "except OSError as e:\n",
        "    print(\"Error: %s : %s\" % (dir_path, e.strerror))\n",
        "\n",
        "model = 0\n",
        "net = 0\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQrjVhBBf-Gs",
        "outputId": "425d5670-8928-4e09-a167-94da93ba68d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: /content/data/models : No such file or directory\n",
            "Error: /content/data/models : No such file or directory\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2rtuFv9DjOc"
      },
      "source": [
        "**Compile Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xJsd6YQ6DjOc"
      },
      "outputs": [],
      "source": [
        "model = Model(inputs=in_layer,outputs=net)\n",
        "adam_coarse =  tf.keras.optimizers.Adam(learning_rate=0.001,epsilon=1e-05)\n",
        "model.compile(optimizer= adam_coarse, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "tbCallBack = kr.callbacks.TensorBoard(log_dir='./data/graph/relu_drop/', histogram_freq=0, write_graph=True, write_images=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVJdJDduDjOd"
      },
      "source": [
        "**Train Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y47GeFu4DjOd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0219c49-432c-4577-eaaa-f3ba24092f19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train on 8092 samples, validate on 2024 samples\n",
            "Epoch 1/5\n",
            "8092/8092 [==============================] - ETA: 0s - loss: 3.2329 - acc: 0.1789"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training_v1.py:2057: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates = self.state_updates\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r8092/8092 [==============================] - 17s 2ms/sample - loss: 3.2329 - acc: 0.1789 - val_loss: 8.7352 - val_acc: 0.0588\n",
            "Epoch 2/5\n",
            "8092/8092 [==============================] - 16s 2ms/sample - loss: 2.5190 - acc: 0.3040 - val_loss: 5.1118 - val_acc: 0.1102\n",
            "Epoch 3/5\n",
            "8092/8092 [==============================] - 16s 2ms/sample - loss: 1.9934 - acc: 0.4182 - val_loss: 2.7745 - val_acc: 0.2609\n",
            "Epoch 4/5\n",
            "8092/8092 [==============================] - 16s 2ms/sample - loss: 1.5053 - acc: 0.5445 - val_loss: 2.7144 - val_acc: 0.3039\n",
            "Epoch 5/5\n",
            "8092/8092 [==============================] - 16s 2ms/sample - loss: 0.9262 - acc: 0.7132 - val_loss: 2.5657 - val_acc: 0.3399\n",
            "Train on 8092 samples, validate on 2024 samples\n",
            "Epoch 6/10\n",
            "8092/8092 [==============================] - 16s 2ms/sample - loss: 0.4415 - acc: 0.8685 - val_loss: 2.5460 - val_acc: 0.3725\n",
            "Epoch 7/10\n",
            "8092/8092 [==============================] - 16s 2ms/sample - loss: 0.1819 - acc: 0.9544 - val_loss: 2.8566 - val_acc: 0.3231\n",
            "Epoch 8/10\n",
            "8092/8092 [==============================] - 16s 2ms/sample - loss: 0.0634 - acc: 0.9883 - val_loss: 2.3560 - val_acc: 0.4155\n",
            "Epoch 9/10\n",
            "8092/8092 [==============================] - 16s 2ms/sample - loss: 0.0238 - acc: 0.9973 - val_loss: 2.4405 - val_acc: 0.4274\n",
            "Epoch 10/10\n",
            "8092/8092 [==============================] - 16s 2ms/sample - loss: 0.0097 - acc: 0.9996 - val_loss: 2.3908 - val_acc: 0.4368\n",
            "Train on 8092 samples, validate on 2024 samples\n",
            "Epoch 11/15\n",
            "8092/8092 [==============================] - 16s 2ms/sample - loss: 0.0058 - acc: 0.9996 - val_loss: 2.4690 - val_acc: 0.4318\n",
            "Epoch 12/15\n",
            "8092/8092 [==============================] - 16s 2ms/sample - loss: 0.0053 - acc: 0.9996 - val_loss: 2.4880 - val_acc: 0.4284\n",
            "Epoch 13/15\n",
            "8092/8092 [==============================] - 16s 2ms/sample - loss: 0.0039 - acc: 0.9998 - val_loss: 2.4872 - val_acc: 0.4397\n",
            "Epoch 14/15\n",
            "8092/8092 [==============================] - 16s 2ms/sample - loss: 0.0028 - acc: 0.9998 - val_loss: 2.4932 - val_acc: 0.4412\n",
            "Epoch 15/15\n",
            "8092/8092 [==============================] - 16s 2ms/sample - loss: 0.0032 - acc: 0.9998 - val_loss: 2.5178 - val_acc: 0.4442\n",
            "Train on 8092 samples, validate on 2024 samples\n",
            "Epoch 16/20\n",
            "8092/8092 [==============================] - 16s 2ms/sample - loss: 0.0016 - acc: 0.9999 - val_loss: 2.5282 - val_acc: 0.4417\n",
            "Epoch 17/20\n",
            "8092/8092 [==============================] - 16s 2ms/sample - loss: 0.0018 - acc: 0.9999 - val_loss: 2.5284 - val_acc: 0.4412\n",
            "Epoch 18/20\n",
            "8092/8092 [==============================] - 16s 2ms/sample - loss: 0.0022 - acc: 0.9999 - val_loss: 2.5340 - val_acc: 0.4397\n",
            "Epoch 19/20\n",
            "8092/8092 [==============================] - 16s 2ms/sample - loss: 0.0019 - acc: 0.9999 - val_loss: 2.5588 - val_acc: 0.4457\n",
            "Epoch 20/20\n",
            "8092/8092 [==============================] - 16s 2ms/sample - loss: 0.0013 - acc: 0.9999 - val_loss: 2.5671 - val_acc: 0.4427\n",
            "Train on 8092 samples, validate on 2024 samples\n",
            "Epoch 21/25\n",
            "8092/8092 [==============================] - 16s 2ms/sample - loss: 0.0018 - acc: 0.9998 - val_loss: 2.5825 - val_acc: 0.4457\n",
            "Epoch 22/25\n",
            "8092/8092 [==============================] - 16s 2ms/sample - loss: 0.0012 - acc: 0.9998 - val_loss: 2.5909 - val_acc: 0.4452\n",
            "Epoch 23/25\n",
            "8092/8092 [==============================] - 16s 2ms/sample - loss: 0.0022 - acc: 0.9998 - val_loss: 2.6020 - val_acc: 0.4461\n",
            "Epoch 24/25\n",
            "8092/8092 [==============================] - 16s 2ms/sample - loss: 0.0011 - acc: 0.9999 - val_loss: 2.5807 - val_acc: 0.4471\n",
            "Epoch 25/25\n",
            "8092/8092 [==============================] - 16s 2ms/sample - loss: 0.0018 - acc: 0.9999 - val_loss: 2.5994 - val_acc: 0.4471\n",
            "Train on 8092 samples, validate on 2024 samples\n",
            "Epoch 26/30\n",
            "8092/8092 [==============================] - 16s 2ms/sample - loss: 0.0011 - acc: 0.9999 - val_loss: 2.6197 - val_acc: 0.4516\n",
            "Epoch 27/30\n",
            "8092/8092 [==============================] - 16s 2ms/sample - loss: 0.0017 - acc: 0.9998 - val_loss: 2.6218 - val_acc: 0.4461\n",
            "Epoch 28/30\n",
            "8092/8092 [==============================] - 16s 2ms/sample - loss: 8.9057e-04 - acc: 0.9999 - val_loss: 2.6272 - val_acc: 0.4447\n",
            "Epoch 29/30\n",
            "8092/8092 [==============================] - 16s 2ms/sample - loss: 0.0019 - acc: 0.9999 - val_loss: 2.6356 - val_acc: 0.4471\n",
            "Epoch 30/30\n",
            "8092/8092 [==============================] - 16s 2ms/sample - loss: 0.0027 - acc: 0.9998 - val_loss: 2.6080 - val_acc: 0.4526\n"
          ]
        }
      ],
      "source": [
        "index= 0\n",
        "step = 5\n",
        "stop = 30\n",
        "batch = 64\n",
        "\n",
        "while index < stop:\n",
        "    model.fit(x_train, y_train, batch_size=batch, initial_epoch=index, epochs=index+step, validation_data=(x_val, y_val), callbacks=[tbCallBack])\n",
        "    index += step\n",
        "    model.save_weights('data/models/model_coarse'+str(index))\n",
        "save_index = index"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index= 0\n",
        "step = 5\n",
        "stop = 40\n",
        "batch = 64\n",
        "while index < stop:\n",
        "    model.fit(x_train_eight, y_train_eight, batch_size=batch, initial_epoch=index, epochs=index+step, validation_data=(x_val_eight, y_val_eight), callbacks=[tbCallBack])\n",
        "    index += step\n",
        "    model.save_weights('data/models/model_coarse'+str(index))\n",
        "save_index = index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKpJz1uddhNc",
        "outputId": "e7d12b0f-ef5d-4cf8-9fff-d4e7f8a6b7b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train on 3128 samples, validate on 348 samples\n",
            "Epoch 1/5\n",
            "3128/3128 [==============================] - ETA: 0s - loss: 2.3780 - acc: 0.4060"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training_v1.py:2057: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates = self.state_updates\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3128/3128 [==============================] - 8s 3ms/sample - loss: 2.3780 - acc: 0.4060 - val_loss: 14.4857 - val_acc: 0.1293\n",
            "Epoch 2/5\n",
            "3128/3128 [==============================] - 6s 2ms/sample - loss: 1.4230 - acc: 0.5521 - val_loss: 28.9500 - val_acc: 0.1121\n",
            "Epoch 3/5\n",
            "3128/3128 [==============================] - 6s 2ms/sample - loss: 0.9822 - acc: 0.6723 - val_loss: 27.6614 - val_acc: 0.1121\n",
            "Epoch 4/5\n",
            "3128/3128 [==============================] - 6s 2ms/sample - loss: 0.7144 - acc: 0.7458 - val_loss: 29.5934 - val_acc: 0.1121\n",
            "Epoch 5/5\n",
            "3128/3128 [==============================] - 6s 2ms/sample - loss: 0.4873 - acc: 0.8274 - val_loss: 15.3162 - val_acc: 0.1264\n",
            "Train on 3128 samples, validate on 348 samples\n",
            "Epoch 6/10\n",
            "3128/3128 [==============================] - 6s 2ms/sample - loss: 0.3274 - acc: 0.8942 - val_loss: 8.4820 - val_acc: 0.1724\n",
            "Epoch 7/10\n",
            "3128/3128 [==============================] - 6s 2ms/sample - loss: 0.2312 - acc: 0.9255 - val_loss: 3.0200 - val_acc: 0.3477\n",
            "Epoch 8/10\n",
            "3128/3128 [==============================] - 6s 2ms/sample - loss: 0.2153 - acc: 0.9293 - val_loss: 2.4726 - val_acc: 0.3879\n",
            "Epoch 9/10\n",
            "3128/3128 [==============================] - 6s 2ms/sample - loss: 0.0841 - acc: 0.9786 - val_loss: 3.2825 - val_acc: 0.3649\n",
            "Epoch 10/10\n",
            "3128/3128 [==============================] - 6s 2ms/sample - loss: 0.0672 - acc: 0.9818 - val_loss: 1.5792 - val_acc: 0.6034\n",
            "Train on 3128 samples, validate on 348 samples\n",
            "Epoch 11/15\n",
            "3128/3128 [==============================] - 6s 2ms/sample - loss: 0.0453 - acc: 0.9882 - val_loss: 1.5983 - val_acc: 0.5517\n",
            "Epoch 12/15\n",
            "3128/3128 [==============================] - 6s 2ms/sample - loss: 0.0238 - acc: 0.9949 - val_loss: 1.5328 - val_acc: 0.6006\n",
            "Epoch 13/15\n",
            "3128/3128 [==============================] - 6s 2ms/sample - loss: 0.0124 - acc: 0.9990 - val_loss: 1.5239 - val_acc: 0.6121\n",
            "Epoch 14/15\n",
            "3128/3128 [==============================] - 6s 2ms/sample - loss: 0.0072 - acc: 0.9990 - val_loss: 1.5786 - val_acc: 0.5920\n",
            "Epoch 15/15\n",
            "3128/3128 [==============================] - 6s 2ms/sample - loss: 0.0072 - acc: 0.9990 - val_loss: 1.6123 - val_acc: 0.5747\n",
            "Train on 3128 samples, validate on 348 samples\n",
            "Epoch 16/20\n",
            "3128/3128 [==============================] - 6s 2ms/sample - loss: 0.0096 - acc: 0.9987 - val_loss: 1.6251 - val_acc: 0.6178\n",
            "Epoch 17/20\n",
            "3128/3128 [==============================] - 6s 2ms/sample - loss: 0.0048 - acc: 0.9997 - val_loss: 1.5027 - val_acc: 0.6264\n",
            "Epoch 18/20\n",
            "3128/3128 [==============================] - 6s 2ms/sample - loss: 0.0046 - acc: 0.9994 - val_loss: 1.5061 - val_acc: 0.6466\n",
            "Epoch 19/20\n",
            "3128/3128 [==============================] - 6s 2ms/sample - loss: 0.0091 - acc: 0.9984 - val_loss: 1.6138 - val_acc: 0.6322\n",
            "Epoch 20/20\n",
            "3128/3128 [==============================] - 6s 2ms/sample - loss: 0.0041 - acc: 0.9997 - val_loss: 1.5711 - val_acc: 0.6207\n",
            "Train on 3128 samples, validate on 348 samples\n",
            "Epoch 21/25\n",
            "3128/3128 [==============================] - 6s 2ms/sample - loss: 0.0062 - acc: 0.9994 - val_loss: 1.6980 - val_acc: 0.6293\n",
            "Epoch 22/25\n",
            "3128/3128 [==============================] - 6s 2ms/sample - loss: 0.0049 - acc: 0.9994 - val_loss: 1.5764 - val_acc: 0.6609\n",
            "Epoch 23/25\n",
            "3128/3128 [==============================] - 6s 2ms/sample - loss: 0.0027 - acc: 0.9994 - val_loss: 1.6566 - val_acc: 0.6466\n",
            "Epoch 24/25\n",
            "3128/3128 [==============================] - 6s 2ms/sample - loss: 0.0143 - acc: 0.9971 - val_loss: 1.8687 - val_acc: 0.5776\n",
            "Epoch 25/25\n",
            "3128/3128 [==============================] - 6s 2ms/sample - loss: 0.0213 - acc: 0.9939 - val_loss: 1.8965 - val_acc: 0.6236\n",
            "Train on 3128 samples, validate on 348 samples\n",
            "Epoch 26/30\n",
            "3128/3128 [==============================] - 6s 2ms/sample - loss: 0.0363 - acc: 0.9885 - val_loss: 2.4207 - val_acc: 0.5144\n",
            "Epoch 27/30\n",
            "3128/3128 [==============================] - 6s 2ms/sample - loss: 0.0828 - acc: 0.9744 - val_loss: 2.8027 - val_acc: 0.5230\n",
            "Epoch 28/30\n",
            "3128/3128 [==============================] - 6s 2ms/sample - loss: 0.1555 - acc: 0.9469 - val_loss: 3.1000 - val_acc: 0.5287\n",
            "Epoch 29/30\n",
            "3128/3128 [==============================] - 6s 2ms/sample - loss: 0.1712 - acc: 0.9412 - val_loss: 3.2710 - val_acc: 0.4598\n",
            "Epoch 30/30\n",
            "3128/3128 [==============================] - 6s 2ms/sample - loss: 0.2251 - acc: 0.9220 - val_loss: 7.3246 - val_acc: 0.3534\n",
            "Train on 3128 samples, validate on 348 samples\n",
            "Epoch 31/35\n",
            "3128/3128 [==============================] - 6s 2ms/sample - loss: 0.1352 - acc: 0.9536 - val_loss: 2.4971 - val_acc: 0.5345\n",
            "Epoch 32/35\n",
            "3128/3128 [==============================] - 6s 2ms/sample - loss: 0.0703 - acc: 0.9760 - val_loss: 2.3243 - val_acc: 0.5431\n",
            "Epoch 33/35\n",
            "3128/3128 [==============================] - 6s 2ms/sample - loss: 0.0498 - acc: 0.9843 - val_loss: 1.8449 - val_acc: 0.5920\n",
            "Epoch 34/35\n",
            "3128/3128 [==============================] - 6s 2ms/sample - loss: 0.0282 - acc: 0.9923 - val_loss: 1.8324 - val_acc: 0.6006\n",
            "Epoch 35/35\n",
            "3128/3128 [==============================] - 6s 2ms/sample - loss: 0.0220 - acc: 0.9942 - val_loss: 1.9449 - val_acc: 0.5833\n",
            "Train on 3128 samples, validate on 348 samples\n",
            "Epoch 36/40\n",
            "3128/3128 [==============================] - 6s 2ms/sample - loss: 0.0127 - acc: 0.9958 - val_loss: 1.7471 - val_acc: 0.6207\n",
            "Epoch 37/40\n",
            "3128/3128 [==============================] - 6s 2ms/sample - loss: 0.0097 - acc: 0.9974 - val_loss: 1.6421 - val_acc: 0.6293\n",
            "Epoch 38/40\n",
            "3128/3128 [==============================] - 6s 2ms/sample - loss: 0.0030 - acc: 0.9997 - val_loss: 1.5620 - val_acc: 0.6207\n",
            "Epoch 39/40\n",
            "3128/3128 [==============================] - 6s 2ms/sample - loss: 0.0058 - acc: 0.9997 - val_loss: 1.5896 - val_acc: 0.6092\n",
            "Epoch 40/40\n",
            "3128/3128 [==============================] - 6s 2ms/sample - loss: 0.0041 - acc: 0.9994 - val_loss: 1.6177 - val_acc: 0.6293\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "doPrf6oODjOe"
      },
      "source": [
        "### Load Most Recent Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m-zzRp0iDjOe"
      },
      "outputs": [],
      "source": [
        "adam_fine =  tf.keras.optimizers.Adam(learning_rate=0.0001,epsilon=1e-05)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HcV-ylYKDjOe"
      },
      "outputs": [],
      "source": [
        "for i in range(len(model.layers)):\n",
        "    model.layers[i].trainable=False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nh5MGsa8DjOe"
      },
      "source": [
        "## Fine-Tuning for Coarse Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KKXGCDnODjOf"
      },
      "outputs": [],
      "source": [
        "y_train_c = np.dot(y_train,fine2coarse)\n",
        "y_val_c = np.dot(y_val,fine2coarse)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train_c.shape)\n",
        "print(y_train.shape)\n",
        "print(fine2coarse.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NOdJQgwA-jiN",
        "outputId": "8dfe8e6a-15a0-46ac-d65a-5992622941f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8092, 9)\n",
            "(8092, 25)\n",
            "(25, 9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iN0JI7ErDjOf"
      },
      "outputs": [],
      "source": [
        "net = Conv2D(512, 3, strides=1, padding='same', activation='relu')(model.layers[-9].output)\n",
        "net = BatchNormalization()(net)\n",
        "# net = Dropout(.5)(net)\n",
        "net = MaxPooling2D((2, 2), padding='valid')(net)\n",
        "\n",
        "net = Flatten()(net)\n",
        "\n",
        "net = Dense(1024, activation='relu')(net)\n",
        "net = BatchNormalization()(net)\n",
        "net = Dropout(.3)(net)\n",
        "out_coarse = Dense(9, activation='softmax')(net)\n",
        "\n",
        "model_c = Model(inputs=in_layer,outputs=out_coarse)\n",
        "model_c.compile(optimizer= adam_coarse, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "for i in range(len(model_c.layers)-1):\n",
        "    model_c.layers[i].set_weights(model.layers[i].get_weights())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afdV_EKCDjOf",
        "outputId": "b44634ac-ee91-47f7-bad2-f98c3ac5d957"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train on 8092 samples, validate on 2024 samples\n",
            "Epoch 31/40\n",
            "8092/8092 [==============================] - ETA: 0s - loss: 1.7772 - acc: 0.4668"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training_v1.py:2057: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates = self.state_updates\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r8092/8092 [==============================] - 7s 910us/sample - loss: 1.7772 - acc: 0.4668 - val_loss: 2.2444 - val_acc: 0.4111\n",
            "Epoch 32/40\n",
            "8092/8092 [==============================] - 7s 829us/sample - loss: 0.8899 - acc: 0.6901 - val_loss: 1.3489 - val_acc: 0.5677\n",
            "Epoch 33/40\n",
            "8092/8092 [==============================] - 7s 832us/sample - loss: 0.4296 - acc: 0.8548 - val_loss: 1.6258 - val_acc: 0.5311\n",
            "Epoch 34/40\n",
            "8092/8092 [==============================] - 7s 834us/sample - loss: 0.1573 - acc: 0.9528 - val_loss: 1.6897 - val_acc: 0.5608\n",
            "Epoch 35/40\n",
            "8092/8092 [==============================] - 7s 840us/sample - loss: 0.0582 - acc: 0.9867 - val_loss: 1.6680 - val_acc: 0.5707\n",
            "Epoch 36/40\n",
            "8092/8092 [==============================] - 7s 839us/sample - loss: 0.0262 - acc: 0.9951 - val_loss: 1.7675 - val_acc: 0.5741\n",
            "Epoch 37/40\n",
            "8092/8092 [==============================] - 7s 838us/sample - loss: 0.0133 - acc: 0.9986 - val_loss: 1.8844 - val_acc: 0.5627\n",
            "Epoch 38/40\n",
            "8092/8092 [==============================] - 7s 835us/sample - loss: 0.0098 - acc: 0.9984 - val_loss: 1.9220 - val_acc: 0.5736\n",
            "Epoch 39/40\n",
            "8092/8092 [==============================] - 7s 833us/sample - loss: 0.0069 - acc: 0.9990 - val_loss: 2.0134 - val_acc: 0.5682\n",
            "Epoch 40/40\n",
            "8092/8092 [==============================] - 7s 838us/sample - loss: 0.0047 - acc: 0.9996 - val_loss: 2.0303 - val_acc: 0.5677\n"
          ]
        }
      ],
      "source": [
        "index = 30\n",
        "step = 10\n",
        "stop = 40\n",
        "\n",
        "while index < stop:\n",
        "    model_c.fit(x_train, y_train_c, batch_size=batch, initial_epoch=index, epochs=index+step, validation_data=(x_val, y_val_c), callbacks=[tbCallBack])\n",
        "    index += step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQv1R7OnDjOf",
        "outputId": "492a593b-848b-44be-b581-857abf7f3972"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train on 8092 samples, validate on 2024 samples\n",
            "Epoch 41/50\n",
            "8092/8092 [==============================] - ETA: 0s - loss: 0.0034 - acc: 0.9998"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training_v1.py:2057: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates = self.state_updates\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r8092/8092 [==============================] - 7s 912us/sample - loss: 0.0034 - acc: 0.9998 - val_loss: 2.4332 - val_acc: 0.5425\n",
            "Epoch 42/50\n",
            "8092/8092 [==============================] - 7s 829us/sample - loss: 0.0327 - acc: 0.9906 - val_loss: 2.7144 - val_acc: 0.5469\n",
            "Epoch 43/50\n",
            "8092/8092 [==============================] - 7s 834us/sample - loss: 0.0763 - acc: 0.9740 - val_loss: 2.7416 - val_acc: 0.5247\n",
            "Epoch 44/50\n",
            "8092/8092 [==============================] - 7s 835us/sample - loss: 0.0714 - acc: 0.9753 - val_loss: 2.4672 - val_acc: 0.5484\n",
            "Epoch 45/50\n",
            "8092/8092 [==============================] - 7s 837us/sample - loss: 0.0305 - acc: 0.9896 - val_loss: 2.5381 - val_acc: 0.5405\n",
            "Epoch 46/50\n",
            "8092/8092 [==============================] - 7s 837us/sample - loss: 0.0165 - acc: 0.9944 - val_loss: 2.5567 - val_acc: 0.5672\n",
            "Epoch 47/50\n",
            "8092/8092 [==============================] - 7s 839us/sample - loss: 0.0154 - acc: 0.9952 - val_loss: 2.5926 - val_acc: 0.5632\n",
            "Epoch 48/50\n",
            "8092/8092 [==============================] - 7s 832us/sample - loss: 0.0221 - acc: 0.9927 - val_loss: 2.7225 - val_acc: 0.5282\n",
            "Epoch 49/50\n",
            "8092/8092 [==============================] - 7s 834us/sample - loss: 0.0268 - acc: 0.9913 - val_loss: 2.7644 - val_acc: 0.5435\n",
            "Epoch 50/50\n",
            "8092/8092 [==============================] - 7s 830us/sample - loss: 0.0256 - acc: 0.9912 - val_loss: 2.7268 - val_acc: 0.5529\n"
          ]
        }
      ],
      "source": [
        "model_c.compile(optimizer= adam_fine, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "stop = 50\n",
        "\n",
        "while index < stop:\n",
        "    model_c.fit(x_train, y_train_c, batch_size=batch, initial_epoch=index, epochs=index+step, validation_data=(x_val, y_val_c), callbacks=[tbCallBack])\n",
        "    index += step"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmbBzJfqDjOg"
      },
      "source": [
        "## Fine-Tuning for Fine Classifiers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7yQPE9aDjOg"
      },
      "source": [
        "### Construct Fine Classifiers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rdK9OAoMDjOg"
      },
      "outputs": [],
      "source": [
        "def fine_model():\n",
        "\n",
        "    net = Conv2D(512, 3, strides=1, padding='same', activation='relu')(model.layers[-9].output)\n",
        "    net = BatchNormalization()(net)\n",
        "    net = MaxPooling2D((2, 2), padding='valid')(net)\n",
        "\n",
        "    net = Flatten()(net)\n",
        "\n",
        "    net = Dense(1024, activation='relu')(net)\n",
        "    net = BatchNormalization()(net)\n",
        "    net = Dropout(.3)(net)\n",
        "    out_fine = Dense(25, activation='softmax')(net)\n",
        "\n",
        "\n",
        "    model_fine = Model(inputs=in_layer,outputs=out_fine)\n",
        "    model_fine.compile(optimizer= adam_coarse,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "    \n",
        "    for i in range(len(model_fine.layers)-1):\n",
        "        model_fine.layers[i].set_weights(model.layers[i].get_weights())\n",
        "    return model_fine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XwMV2BNQDjOg"
      },
      "outputs": [],
      "source": [
        "fine_models = {'models' : [{} for i in range(coarse_categories)], 'yhf' : [{} for i in range(coarse_categories)]}\n",
        "for i in range(coarse_categories):\n",
        "    model_i = fine_model()\n",
        "    fine_models['models'][i] = model_i"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3bZP_2CDjOg"
      },
      "source": [
        "### Train Fine Classifiers on Respective Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p7kjaEpnDjOh"
      },
      "outputs": [],
      "source": [
        "def get_error(y,yh):\n",
        "    # Threshold \n",
        "    yht = np.zeros(np.shape(yh))\n",
        "    yht[np.arange(len(yh)), yh.argmax(1)] = 1\n",
        "    # Evaluate Error\n",
        "    error = np.count_nonzero(np.count_nonzero(y-yht,1))/len(y)\n",
        "    return error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 959
        },
        "id": "qVkFtywwDjOh",
        "outputId": "d688bcbf-a3ca-4980-beb1-0b3aba35a9db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train on 637 samples, validate on 161 samples\n",
            "Epoch 1/5\n",
            "637/637 [==============================] - 2s 3ms/sample - loss: 0.0394 - acc: 0.9906 - val_loss: 1.7424 - val_acc: 0.7888\n",
            "Epoch 2/5\n",
            "637/637 [==============================] - 1s 1ms/sample - loss: 0.0469 - acc: 0.9874 - val_loss: 1.5489 - val_acc: 0.8012\n",
            "Epoch 3/5\n",
            "637/637 [==============================] - 1s 1ms/sample - loss: 0.0221 - acc: 0.9953 - val_loss: 1.3969 - val_acc: 0.8012\n",
            "Epoch 4/5\n",
            "637/637 [==============================] - 1s 1ms/sample - loss: 0.0393 - acc: 0.9859 - val_loss: 1.1090 - val_acc: 0.8261\n",
            "Epoch 5/5\n",
            "637/637 [==============================] - 1s 1ms/sample - loss: 0.0105 - acc: 0.9969 - val_loss: 1.0110 - val_acc: 0.8199\n",
            "Train on 637 samples, validate on 161 samples\n",
            "Epoch 6/10\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-70-4a97728ed7d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mfine_models\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'models'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_tix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_vix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_vix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training_v1.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    794\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    795\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 796\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    797\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training_arrays_v1.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    656\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 658\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    659\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training_arrays_v1.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   4274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4275\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 4276\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   4277\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4278\u001b[0m     output_structure = tf.nest.pack_sequence_as(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1480\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1481\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1482\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1483\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1484\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: 2 root error(s) found.\n  (0) RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[64,64,128,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node batch_normalization_35/cond/FusedBatchNormV3}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n\t [[loss_32/mul/_5485]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n  (1) RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[64,64,128,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node batch_normalization_35/cond/FusedBatchNormV3}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n0 successful operations.\n0 derived errors ignored."
          ]
        }
      ],
      "source": [
        "for i in range(coarse_categories):\n",
        "    index= 0\n",
        "    step = 5\n",
        "    stop = 5\n",
        "    \n",
        "    # Get all training data for the coarse category\n",
        "    ix = np.where([(y_train[:,j]==1) for j in [k for k, e in enumerate(fine2coarse[:,i]) if e != 0]])[1]\n",
        "    x_tix = x_train[ix]\n",
        "    y_tix = y_train[ix]\n",
        "    \n",
        "    # Get all validation data for the coarse category\n",
        "    ix_v = np.where([(y_val[:,j]==1) for j in [k for k, e in enumerate(fine2coarse[:,i]) if e != 0]])[1]\n",
        "    x_vix = x_val[ix_v]\n",
        "    y_vix = y_val[ix_v]\n",
        "    \n",
        "    while index < stop:\n",
        "        fine_models['models'][i].fit(x_tix, y_tix, batch_size=16, initial_epoch=index, epochs=index+step, validation_data=(x_vix, y_vix))\n",
        "        index += step\n",
        "    \n",
        "    fine_models['models'][i].compile(optimizer=adam_fine, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    stop = 10\n",
        "\n",
        "    while index < stop:\n",
        "        fine_models['models'][i].fit(x_tix, y_tix, batch_size=batch, initial_epoch=index, epochs=index+step, validation_data=(x_vix, y_vix))\n",
        "        index += step\n",
        "        \n",
        "    yh_f = fine_models['models'][i].predict(x_val[ix_v], batch_size=batch)\n",
        "    print('Fine Classifier '+str(i)+' Error: '+str(get_error(y_val[ix_v],yh_f))) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "DHEcsvXyDjOh"
      },
      "source": [
        "## Probabilistic Averaging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c1Hf7yQfDjOh"
      },
      "outputs": [],
      "source": [
        "def eval_hdcnn(X, y):\n",
        "    yh = np.zeros(np.shape(y))\n",
        "    \n",
        "    yh_s = model.predict(X, batch_size=batch)\n",
        "    \n",
        "    print('Single Classifier Error: '+str(get_error(y,yh_s)))\n",
        "    \n",
        "    yh_c = model_c.predict(X, batch_size=batch)\n",
        "    y_c = np.dot(y,fine2coarse)\n",
        "    \n",
        "    print('Coarse Classifier Error: '+str(get_error(y_c,yh_c)))\n",
        "\n",
        "    for i in range(coarse_categories):\n",
        "        if i%5 == 0:\n",
        "            print(\"Evaluating Fine Classifier: \", str(i))\n",
        "        fine_models['yhf'][i] = fine_models['models'][i].predict(X, batch_size=batch)\n",
        "        \n",
        "        yh += np.multiply(yh_c[:,i].reshape((len(y)),1), fine_models['yhf'][i])\n",
        "    \n",
        "    print('Overall Error: '+str(get_error(y,yh)))\n",
        "    return yh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6QLOBqDDjOi",
        "outputId": "5ee16b27-7f60-468c-cd6f-45d77852ed0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training_v1.py:2079: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Single Classifier Error: 0.6556\n",
            "Coarse Classifier Error: 0.406\n",
            "Evaluating Fine Classifier:  0\n",
            "Evaluating Fine Classifier:  5\n",
            "Evaluating Fine Classifier:  10\n",
            "Evaluating Fine Classifier:  15\n",
            "Overall Error: 0.5764\n"
          ]
        }
      ],
      "source": [
        "yh = eval_hdcnn(x_val,y_val)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "kQnQaFB7kJ7S"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "hdcnn2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Environment (conda_tensorflow_p36)",
      "language": "python",
      "name": "conda_tensorflow_p36"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "toc": {
      "colors": {
        "hover_highlight": "#DAA520",
        "running_highlight": "#FF0000",
        "selected_highlight": "#FFD700"
      },
      "moveMenuLeft": true,
      "nav_menu": {
        "height": "12px",
        "width": "252px"
      },
      "navigate_menu": true,
      "number_sections": true,
      "sideBar": true,
      "threshold": 4,
      "toc_cell": false,
      "toc_section_display": "block",
      "toc_window_display": false,
      "widenNotebook": false
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}