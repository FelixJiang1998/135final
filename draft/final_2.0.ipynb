{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "gather": {
     "logged": 1651503350455
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader, Subset, Dataset, ConcatDataset\n",
    "from torchvision.datasets import DatasetFolder\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "Neuro network structure:\n",
    "Layer1: 3 \\* 3 \\* 64 filter with stride of 1, padding of 1 and max pooling of 2 \\* 2.  \n",
    "Layer2: 3 \\* 3 \\* 128 filter with stride of 1, padding of 1 and max pooling of 2 \\* 2.  \n",
    "Layer3: 3 \\* 3 \\* 256 filter with stride of 1, padding of 1 and max pooling of 2 \\* 2.  \n",
    "\n",
    "Fully connected layer: 256 \\* 16 \\* 16 -> 256, 1 -> 4 (items of class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class NeuroNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuroNetwork, self).__init__()\n",
    "        first_layer = 64\n",
    "        second_layer = 128\n",
    "        third_layer = 256\n",
    "        forth_layer = 512\n",
    "        fc_layer = 1024\n",
    "        output = 25\n",
    "        self.cnn_layers = nn.Sequential(\n",
    "            # First layer\n",
    "            nn.Conv2d(in_channels=3,  # RGB 3 layer3\n",
    "                      out_channels=first_layer,  # Output layer -- the number of filters\n",
    "                      kernel_size=3,  # Size of filter --3*3\n",
    "                      stride=1,\n",
    "                      padding=1),\n",
    "            nn.BatchNorm2d(first_layer),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "\n",
    "            # Second layer\n",
    "            nn.Conv2d(first_layer, second_layer, 3, 1, 1),\n",
    "            nn.BatchNorm2d(second_layer),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            # Third layer\n",
    "            nn.Conv2d(second_layer, third_layer, 3, 1, 1),\n",
    "            nn.BatchNorm2d(third_layer),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            # Forth layer\n",
    "            nn.Conv2d(third_layer, forth_layer, 3, 1, 1),\n",
    "            nn.BatchNorm2d(forth_layer),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(forth_layer * 8 * 8, fc_layer),\n",
    "            nn.BatchNorm1d(fc_layer),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(fc_layer, output)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cnn_layers(x)\n",
    "\n",
    "        x = x.flatten(1)\n",
    "        visual_item = x.view(x.size(0), -1)\n",
    "        x = self.fc_layers(x)\n",
    "        return x, visual_item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Pre-process the raw data:\n",
    "\n",
    "1. Do data augmentation\n",
    "2. by resize to 128*128\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_tfm = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(size=256, scale=(0.7, 1.0)),\n",
    "    transforms.RandomRotation(degrees=25),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_tfm = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load Data\n",
    "train_set = DatasetFolder(\"dataset/arcDataset\",\n",
    "                          loader=lambda x: Image.open(x).convert(\"RGB\"),\n",
    "                          extensions=\"jpg\",\n",
    "                          transform=train_tfm)\n",
    "test_set = DatasetFolder(\"dataset/arcValidset\",\n",
    "                         loader=lambda x: Image.open(x).convert(\"RGB\"),\n",
    "                         extensions=\"jpg\",\n",
    "                         transform=test_tfm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "gather": {
     "logged": 1651548558680
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(135)\n",
    "# Batch size of 128\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# CrossEntropy loss are applied\n",
    "cross_entropy = nn.CrossEntropyLoss()\n",
    "\n",
    "cnn = NeuroNetwork().to(device)\n",
    "cnn.device = device\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "\n",
    "train_loss_record = []\n",
    "valid_loss_record = []\n",
    "train_acc_record = []\n",
    "valid_acc_record = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def save_model():\n",
    "    checkpoint = {\n",
    "        \"net\": cnn.state_dict(),\n",
    "        'optimizer':optimizer.state_dict(),\n",
    "        \"epoch\": epoch\n",
    "    }\n",
    "\n",
    "    fomat_time = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())\n",
    "\n",
    "    torch.save(checkpoint, 'models/checkpoint/autosave_'+fomat_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\84157\\AppData\\Local\\Temp\\ipykernel_11520\\1038361326.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  acc = torch.tensor(predict.argmax(dim=-1) == labels.to(device)).float().mean()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Train | 001/150 ] loss = 2.64705, acc = 0.21903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\84157\\AppData\\Local\\Temp\\ipykernel_11520\\1038361326.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  acc = torch.tensor(predict.argmax(dim=-1) == labels.to(device)).float().mean()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "squeezing data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program files\\Python\\Python3.10\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:790: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
      "  warnings.warn(\n",
      "D:\\Program files\\Python\\Python3.10\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:982: FutureWarning: The PCA initialization in TSNE will change to have the standard deviation of PC1 equal to 1e-4 in 1.2. This will ensure better convergence.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Image size of 349x2901722 pixels is too large. It must be less than 2^16 in each direction.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "File \u001B[1;32mD:\\Program files\\Python\\Python3.10\\lib\\site-packages\\IPython\\core\\formatters.py:339\u001B[0m, in \u001B[0;36mBaseFormatter.__call__\u001B[1;34m(self, obj)\u001B[0m\n\u001B[0;32m    337\u001B[0m     \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[0;32m    338\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 339\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mprinter\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    340\u001B[0m \u001B[38;5;66;03m# Finally look for special method names\u001B[39;00m\n\u001B[0;32m    341\u001B[0m method \u001B[38;5;241m=\u001B[39m get_real_method(obj, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprint_method)\n",
      "File \u001B[1;32mD:\\Program files\\Python\\Python3.10\\lib\\site-packages\\IPython\\core\\pylabtools.py:151\u001B[0m, in \u001B[0;36mprint_figure\u001B[1;34m(fig, fmt, bbox_inches, base64, **kwargs)\u001B[0m\n\u001B[0;32m    148\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbackend_bases\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m FigureCanvasBase\n\u001B[0;32m    149\u001B[0m     FigureCanvasBase(fig)\n\u001B[1;32m--> 151\u001B[0m fig\u001B[38;5;241m.\u001B[39mcanvas\u001B[38;5;241m.\u001B[39mprint_figure(bytes_io, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkw)\n\u001B[0;32m    152\u001B[0m data \u001B[38;5;241m=\u001B[39m bytes_io\u001B[38;5;241m.\u001B[39mgetvalue()\n\u001B[0;32m    153\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m fmt \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msvg\u001B[39m\u001B[38;5;124m'\u001B[39m:\n",
      "File \u001B[1;32mD:\\Program files\\Python\\Python3.10\\lib\\site-packages\\matplotlib\\backend_bases.py:2319\u001B[0m, in \u001B[0;36mFigureCanvasBase.print_figure\u001B[1;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001B[0m\n\u001B[0;32m   2315\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   2316\u001B[0m     \u001B[38;5;66;03m# _get_renderer may change the figure dpi (as vector formats\u001B[39;00m\n\u001B[0;32m   2317\u001B[0m     \u001B[38;5;66;03m# force the figure dpi to 72), so we need to set it again here.\u001B[39;00m\n\u001B[0;32m   2318\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m cbook\u001B[38;5;241m.\u001B[39m_setattr_cm(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfigure, dpi\u001B[38;5;241m=\u001B[39mdpi):\n\u001B[1;32m-> 2319\u001B[0m         result \u001B[38;5;241m=\u001B[39m print_method(\n\u001B[0;32m   2320\u001B[0m             filename,\n\u001B[0;32m   2321\u001B[0m             facecolor\u001B[38;5;241m=\u001B[39mfacecolor,\n\u001B[0;32m   2322\u001B[0m             edgecolor\u001B[38;5;241m=\u001B[39medgecolor,\n\u001B[0;32m   2323\u001B[0m             orientation\u001B[38;5;241m=\u001B[39morientation,\n\u001B[0;32m   2324\u001B[0m             bbox_inches_restore\u001B[38;5;241m=\u001B[39m_bbox_inches_restore,\n\u001B[0;32m   2325\u001B[0m             \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   2326\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m   2327\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m bbox_inches \u001B[38;5;129;01mand\u001B[39;00m restore_bbox:\n",
      "File \u001B[1;32mD:\\Program files\\Python\\Python3.10\\lib\\site-packages\\matplotlib\\backend_bases.py:1648\u001B[0m, in \u001B[0;36m_check_savefig_extra_args.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m   1640\u001B[0m     _api\u001B[38;5;241m.\u001B[39mwarn_deprecated(\n\u001B[0;32m   1641\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m3.3\u001B[39m\u001B[38;5;124m'\u001B[39m, name\u001B[38;5;241m=\u001B[39mname, removal\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m3.6\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m   1642\u001B[0m         message\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m%(name)s\u001B[39;00m\u001B[38;5;124m() got unexpected keyword argument \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m   1643\u001B[0m                 \u001B[38;5;241m+\u001B[39m arg \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m which is no longer supported as of \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m   1644\u001B[0m                 \u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m%(since)s\u001B[39;00m\u001B[38;5;124m and will become an error \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m   1645\u001B[0m                 \u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m%(removal)s\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m   1646\u001B[0m     kwargs\u001B[38;5;241m.\u001B[39mpop(arg)\n\u001B[1;32m-> 1648\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mD:\\Program files\\Python\\Python3.10\\lib\\site-packages\\matplotlib\\_api\\deprecation.py:412\u001B[0m, in \u001B[0;36mdelete_parameter.<locals>.wrapper\u001B[1;34m(*inner_args, **inner_kwargs)\u001B[0m\n\u001B[0;32m    402\u001B[0m     deprecation_addendum \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    403\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIf any parameter follows \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m!r}\u001B[39;00m\u001B[38;5;124m, they should be passed as \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    404\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mkeyword, not positionally.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    405\u001B[0m     warn_deprecated(\n\u001B[0;32m    406\u001B[0m         since,\n\u001B[0;32m    407\u001B[0m         name\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mrepr\u001B[39m(name),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    410\u001B[0m                  \u001B[38;5;28;01melse\u001B[39;00m deprecation_addendum,\n\u001B[0;32m    411\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m--> 412\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39minner_args, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39minner_kwargs)\n",
      "File \u001B[1;32mD:\\Program files\\Python\\Python3.10\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:540\u001B[0m, in \u001B[0;36mFigureCanvasAgg.print_png\u001B[1;34m(self, filename_or_obj, metadata, pil_kwargs, *args)\u001B[0m\n\u001B[0;32m    490\u001B[0m \u001B[38;5;129m@_check_savefig_extra_args\u001B[39m\n\u001B[0;32m    491\u001B[0m \u001B[38;5;129m@_api\u001B[39m\u001B[38;5;241m.\u001B[39mdelete_parameter(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m3.5\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124margs\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    492\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mprint_png\u001B[39m(\u001B[38;5;28mself\u001B[39m, filename_or_obj, \u001B[38;5;241m*\u001B[39margs,\n\u001B[0;32m    493\u001B[0m               metadata\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, pil_kwargs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m    494\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    495\u001B[0m \u001B[38;5;124;03m    Write the figure to a PNG file.\u001B[39;00m\n\u001B[0;32m    496\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    538\u001B[0m \u001B[38;5;124;03m        *metadata*, including the default 'Software' key.\u001B[39;00m\n\u001B[0;32m    539\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 540\u001B[0m     \u001B[43mFigureCanvasAgg\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdraw\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    541\u001B[0m     mpl\u001B[38;5;241m.\u001B[39mimage\u001B[38;5;241m.\u001B[39mimsave(\n\u001B[0;32m    542\u001B[0m         filename_or_obj, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbuffer_rgba(), \u001B[38;5;28mformat\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpng\u001B[39m\u001B[38;5;124m\"\u001B[39m, origin\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mupper\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    543\u001B[0m         dpi\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfigure\u001B[38;5;241m.\u001B[39mdpi, metadata\u001B[38;5;241m=\u001B[39mmetadata, pil_kwargs\u001B[38;5;241m=\u001B[39mpil_kwargs)\n",
      "File \u001B[1;32mD:\\Program files\\Python\\Python3.10\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:431\u001B[0m, in \u001B[0;36mFigureCanvasAgg.draw\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    429\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdraw\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    430\u001B[0m     \u001B[38;5;66;03m# docstring inherited\u001B[39;00m\n\u001B[1;32m--> 431\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrenderer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_renderer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcleared\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m    432\u001B[0m     \u001B[38;5;66;03m# Acquire a lock on the shared font cache.\u001B[39;00m\n\u001B[0;32m    433\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m RendererAgg\u001B[38;5;241m.\u001B[39mlock, \\\n\u001B[0;32m    434\u001B[0m          (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtoolbar\u001B[38;5;241m.\u001B[39m_wait_cursor_for_draw_cm() \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtoolbar\n\u001B[0;32m    435\u001B[0m           \u001B[38;5;28;01melse\u001B[39;00m nullcontext()):\n",
      "File \u001B[1;32mD:\\Program files\\Python\\Python3.10\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:447\u001B[0m, in \u001B[0;36mFigureCanvasAgg.get_renderer\u001B[1;34m(self, cleared)\u001B[0m\n\u001B[0;32m    444\u001B[0m reuse_renderer \u001B[38;5;241m=\u001B[39m (\u001B[38;5;28mhasattr\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrenderer\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    445\u001B[0m                   \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_lastKey\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;241m==\u001B[39m key)\n\u001B[0;32m    446\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m reuse_renderer:\n\u001B[1;32m--> 447\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrenderer \u001B[38;5;241m=\u001B[39m \u001B[43mRendererAgg\u001B[49m\u001B[43m(\u001B[49m\u001B[43mw\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mh\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfigure\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdpi\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    448\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lastKey \u001B[38;5;241m=\u001B[39m key\n\u001B[0;32m    449\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m cleared:\n",
      "File \u001B[1;32mD:\\Program files\\Python\\Python3.10\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:93\u001B[0m, in \u001B[0;36mRendererAgg.__init__\u001B[1;34m(self, width, height, dpi)\u001B[0m\n\u001B[0;32m     91\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mwidth \u001B[38;5;241m=\u001B[39m width\n\u001B[0;32m     92\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mheight \u001B[38;5;241m=\u001B[39m height\n\u001B[1;32m---> 93\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_renderer \u001B[38;5;241m=\u001B[39m \u001B[43m_RendererAgg\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mint\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mwidth\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mint\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mheight\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdpi\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     94\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_filter_renderers \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m     96\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_update_methods()\n",
      "\u001B[1;31mValueError\u001B[0m: Image size of 349x2901722 pixels is too large. It must be less than 2^16 in each direction."
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Test | 001/150 ] loss = 2.66741, acc = 0.23182\n",
      "[Time cost | 001/150]: 1126.3174s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [9]\u001B[0m, in \u001B[0;36m<cell line: 28>\u001B[1;34m()\u001B[0m\n\u001B[0;32m     26\u001B[0m n_epochs \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m150\u001B[39m\n\u001B[0;32m     27\u001B[0m best_acc \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.0\u001B[39m\n\u001B[1;32m---> 28\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(n_epochs):\n\u001B[0;32m     29\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEpoch: \u001B[39m\u001B[38;5;124m\"\u001B[39m, epoch)\n\u001B[0;32m     30\u001B[0m     start_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n",
      "Input \u001B[1;32mIn [9]\u001B[0m, in \u001B[0;36m<cell line: 28>\u001B[1;34m()\u001B[0m\n\u001B[0;32m     26\u001B[0m n_epochs \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m150\u001B[39m\n\u001B[0;32m     27\u001B[0m best_acc \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.0\u001B[39m\n\u001B[1;32m---> 28\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(n_epochs):\n\u001B[0;32m     29\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEpoch: \u001B[39m\u001B[38;5;124m\"\u001B[39m, epoch)\n\u001B[0;32m     30\u001B[0m     start_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_310_64.pyx:1179\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_310_64.SafeCallWrapper.__call__\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_310_64.pyx:620\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_310_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_310_64.pyx:1095\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_310_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_310_64.pyx:1053\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_310_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mD:\\Program files\\JetBrains\\PyCharm 2020.3.3\\plugins\\python\\helpers-pro\\jupyter_debug\\pydev_jupyter_plugin.py:165\u001B[0m, in \u001B[0;36mstop\u001B[1;34m(plugin, pydb, frame, event, args, stop_info, arg, step_cmd)\u001B[0m\n\u001B[0;32m    163\u001B[0m     frame \u001B[38;5;241m=\u001B[39m suspend_jupyter(main_debugger, thread, frame, step_cmd)\n\u001B[0;32m    164\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m frame:\n\u001B[1;32m--> 165\u001B[0m         \u001B[43mmain_debugger\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdo_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    166\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m    167\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[1;32mD:\\Program files\\JetBrains\\PyCharm 2020.3.3\\plugins\\python\\helpers\\pydev\\pydevd.py:1155\u001B[0m, in \u001B[0;36mPyDB.do_wait_suspend\u001B[1;34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[0m\n\u001B[0;32m   1152\u001B[0m         from_this_thread\u001B[38;5;241m.\u001B[39mappend(frame_id)\n\u001B[0;32m   1154\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_threads_suspended_single_notification\u001B[38;5;241m.\u001B[39mnotify_thread_suspended(thread_id, stop_reason):\n\u001B[1;32m-> 1155\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_do_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msuspend_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrom_this_thread\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Program files\\JetBrains\\PyCharm 2020.3.3\\plugins\\python\\helpers\\pydev\\pydevd.py:1170\u001B[0m, in \u001B[0;36mPyDB._do_wait_suspend\u001B[1;34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[0m\n\u001B[0;32m   1167\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_mpl_hook()\n\u001B[0;32m   1169\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocess_internal_commands()\n\u001B[1;32m-> 1170\u001B[0m         \u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0.01\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1172\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcancel_async_evaluation(get_current_thread_id(thread), \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mid\u001B[39m(frame)))\n\u001B[0;32m   1174\u001B[0m \u001B[38;5;66;03m# process any stepping instructions\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "def plot_with_labels(lowDWeights, labels):\n",
    "    # plt.cla()\n",
    "    # fig, ax = plt.subplots()\n",
    "    X, Y = lowDWeights[:, 0], lowDWeights[:, 1]\n",
    "    labels = np.ravel(labels)\n",
    "    classes = list(np.unique(labels))\n",
    "    markers = 'os' * len(classes)\n",
    "    colors = plt.cm.rainbow(np.linspace(0, 1, len(classes)))\n",
    "    for x, y, s in zip(X, Y, labels):\n",
    "        # c = cm.rainbow(int(255 * s / 9))\n",
    "        # plt.text(x, y, s, backgroundcolor=c, fontsize=9)\n",
    "        i = int(s)\n",
    "        plt.scatter(x, y, marker=markers[i], c=[colors[i]], alpha=0.3)\n",
    "    plt.xlim(X.min(), X.max())\n",
    "    plt.ylim(Y.min(), Y.max())\n",
    "    plt.title('Visualize last layer')\n",
    "\n",
    "    plt.legend()\n",
    "    plt.axis(\"off\")\n",
    "    # fig.set_facecolor('k')\n",
    "    plt.show()\n",
    "\n",
    "# plt.ion()\n",
    "\n",
    "# Train for 20 times rounds\n",
    "n_epochs = 150\n",
    "best_acc = 0.0\n",
    "for epoch in range(n_epochs):\n",
    "    print(\"Epoch: \", epoch)\n",
    "    start_time = time.time()\n",
    "\n",
    "    cnn.train()\n",
    "\n",
    "    train_loss = []\n",
    "    train_acc = []\n",
    "\n",
    "    for batch in train_loader:\n",
    "        data, labels = batch\n",
    "\n",
    "        predict, _ = cnn(data.to(device))\n",
    "        loss = cross_entropy(predict, labels.to(device))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        acc = torch.tensor(predict.argmax(dim=-1) == labels.to(device)).float().mean()\n",
    "        train_loss.append(loss.item())\n",
    "        train_acc.append(acc)\n",
    "\n",
    "    train_loss = sum(train_loss) / len(train_loss)\n",
    "    train_acc = sum(train_acc) / len(train_acc)\n",
    "    print(f\"[ Train | {epoch + 1:03d}/{n_epochs:03d} ] loss = {train_loss:.5f}, acc = {train_acc:.5f}\")\n",
    "\n",
    "    cnn.eval()\n",
    "\n",
    "    test_loss = []\n",
    "    test_acc = []\n",
    "    visual_label_set = []\n",
    "    visual_predict_set = []\n",
    "    for batch in test_loader:\n",
    "        data, labels = batch\n",
    "\n",
    "        with torch.no_grad():\n",
    "            predict, last_layer_item = cnn(data.to(device))\n",
    "\n",
    "        loss = cross_entropy(predict, labels.to(device))\n",
    "\n",
    "        acc = torch.tensor(predict.argmax(dim=-1) == labels.to(device)).float().mean()\n",
    "\n",
    "        test_loss.append(loss.item())\n",
    "        test_acc.append(acc)\n",
    "        visual_predict_set.append(last_layer_item)\n",
    "        visual_label_set.append(labels.to(device).unsqueeze(-1))\n",
    "    print(\"squeezing data\")\n",
    "    v_last_layer_item = torch.vstack(visual_predict_set)\n",
    "    v_labels = torch.vstack(visual_label_set)\n",
    "\n",
    "\n",
    "    print(\"visualizing\")\n",
    "    # Visualization of trained flatten layer (T-SNE)\n",
    "    tsne = TSNE(perplexity=30, n_components=2, init='pca', n_iter=5000)\n",
    "    low_dim_embs = tsne.fit_transform(v_last_layer_item.data.numpy()[:, :])\n",
    "    labels = v_labels.to(device).numpy()[:]\n",
    "    plot_with_labels(low_dim_embs, labels)\n",
    "\n",
    "    valid_loss = sum(test_loss) / len(test_loss)\n",
    "    valid_acc = sum(test_acc) / len(test_acc)\n",
    "\n",
    "    print(f\"[ Test | {epoch + 1:03d}/{n_epochs:03d} ] loss = {valid_loss:.5f}, acc = {valid_acc:.5f}\")\n",
    "\n",
    "    if valid_acc > best_acc:\n",
    "        best_acc = valid_acc\n",
    "\n",
    "    train_loss_record.append(train_loss)\n",
    "    valid_loss_record.append(valid_loss)\n",
    "    train_acc_record.append(train_acc)\n",
    "    valid_acc_record.append(valid_acc)\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    print(f\"[Time cost | {epoch + 1:03d}/{n_epochs:03d}]:{end_time - start_time: .4f}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x = np.arange(len(train_acc_record))\n",
    "plt.plot(x, train_acc_record, color=\"blue\", label=\"Train\")\n",
    "plt.plot(x, valid_acc_record, color=\"red\", label=\"Valid\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()\n",
    "\n",
    "x = np.arange(len(train_loss_record))\n",
    "plt.plot(x, train_loss_record, color=\"blue\", label=\"Train\")\n",
    "plt.plot(x, valid_loss_record, color=\"red\", label=\"Valid\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "azureml_py38_pt_tf"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}